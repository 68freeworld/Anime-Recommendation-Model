{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91af38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # For converting text data into TF-IDF vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # For computing cosine similarity between vectors\n",
    "from scipy.spatial.distance import pdist, squareform  # For pairwise distance computations and converting to a square matrix\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc6e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- load ----------\n",
    "with open(\"rating_df_final.pk\", \"rb\") as f:\n",
    "    rating_df = pickle.load(f)\n",
    "with open(\"anime_df_final.pk\", \"rb\") as f:\n",
    "    anime_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b264fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_name</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Score</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Score_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>5114</td>\n",
       "      <td>Action, Military, Adventure, Comedy, Drama, Ma...</td>\n",
       "      <td>9.19</td>\n",
       "      <td>\"In order for something to be obtained, someth...</td>\n",
       "      <td>9.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shingeki no Kyojin: The Final Season</td>\n",
       "      <td>40028</td>\n",
       "      <td>Action, Military, Mystery, Super Power, Drama,...</td>\n",
       "      <td>9.17</td>\n",
       "      <td>Gabi Braun and Falco Grice have been training ...</td>\n",
       "      <td>9.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>9253</td>\n",
       "      <td>Thriller, Sci-Fi</td>\n",
       "      <td>9.11</td>\n",
       "      <td>The self-proclaimed mad scientist Rintarou Oka...</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hunter x Hunter (2011)</td>\n",
       "      <td>11061</td>\n",
       "      <td>Action, Adventure, Fantasy, Shounen, Super Power</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Hunter x Hunter is set in a world where Hunter...</td>\n",
       "      <td>9.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>38524</td>\n",
       "      <td>Action, Drama, Fantasy, Military, Mystery, Sho...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>9.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             anime_name  anime_id  \\\n",
       "0      Fullmetal Alchemist: Brotherhood      5114   \n",
       "1  Shingeki no Kyojin: The Final Season     40028   \n",
       "2                           Steins;Gate      9253   \n",
       "3                Hunter x Hunter (2011)     11061   \n",
       "4    Shingeki no Kyojin Season 3 Part 2     38524   \n",
       "\n",
       "                                              Genres Score  \\\n",
       "0  Action, Military, Adventure, Comedy, Drama, Ma...  9.19   \n",
       "1  Action, Military, Mystery, Super Power, Drama,...  9.17   \n",
       "2                                   Thriller, Sci-Fi  9.11   \n",
       "3   Action, Adventure, Fantasy, Shounen, Super Power   9.1   \n",
       "4  Action, Drama, Fantasy, Military, Mystery, Sho...   9.1   \n",
       "\n",
       "                                            Synopsis  Score_num  \n",
       "0  \"In order for something to be obtained, someth...       9.19  \n",
       "1  Gabi Braun and Falco Grice have been training ...       9.17  \n",
       "2  The self-proclaimed mad scientist Rintarou Oka...       9.11  \n",
       "3  Hunter x Hunter is set in a world where Hunter...       9.10  \n",
       "4  Seeking to restore humanity's diminishing hope...       9.10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e40999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>anime_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>36</td>\n",
       "      <td>6512</td>\n",
       "      <td>7</td>\n",
       "      <td>Nyan Koi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>36</td>\n",
       "      <td>5958</td>\n",
       "      <td>7</td>\n",
       "      <td>Sora no Otoshimono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>36</td>\n",
       "      <td>6802</td>\n",
       "      <td>8</td>\n",
       "      <td>So Ra No Wo To</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>36</td>\n",
       "      <td>17187</td>\n",
       "      <td>8</td>\n",
       "      <td>Koukaku Kidoutai Arise: Ghost in the Shell - B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>36</td>\n",
       "      <td>16498</td>\n",
       "      <td>8</td>\n",
       "      <td>Shingeki no Kyojin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  anime_id  rating  \\\n",
       "4511       36      6512       7   \n",
       "4512       36      5958       7   \n",
       "4513       36      6802       8   \n",
       "4514       36     17187       8   \n",
       "4515       36     16498       8   \n",
       "\n",
       "                                             anime_name  \n",
       "4511                                          Nyan Koi!  \n",
       "4512                                 Sora no Otoshimono  \n",
       "4513                                     So Ra No Wo To  \n",
       "4514  Koukaku Kidoutai Arise: Ghost in the Shell - B...  \n",
       "4515                                 Shingeki no Kyojin  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be3fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_jaccard(\n",
    "    title,\n",
    "    anime_df,\n",
    "    top_n=10,\n",
    "    precomputed=None  # None, DataFrame \n",
    "):\n",
    "    \"\"\"\n",
    "    recommend_by_jaccard is a function that recommends similar anime using Jaccard similarity\n",
    "    based on either Genres or Themes.\n",
    "\n",
    "    :param title: str\n",
    "        The anime title (anime_name) to base recommendations on.\n",
    "\n",
    "    :param anime_df: pd.DataFrame\n",
    "        DataFrame containing at least 'anime_name' and the selected feature column ('Genres' or 'Themes').\n",
    "\n",
    "    :param top_n: int\n",
    "        Number of top similar results to return.\n",
    "\n",
    "    :param precomputed: np.ndarray or None\n",
    "        Optional precomputed Jaccard distance array to avoid recalculating distances.\n",
    "\n",
    "    :return: dict\n",
    "        A dictionary with:\n",
    "            { \"top\": pd.Series } — the top-N most similar anime and their similarity scores.\n",
    "    \"\"\"\n",
    "\n",
    "    type = 'Genres'\n",
    "    # Check if title exists in the dataset\n",
    "    if title not in anime_df['anime_name'].values:\n",
    "        raise ValueError(f\"'{title}' not found in dataset.\")\n",
    "\n",
    "    def compute_jaccard(df, col):\n",
    "        cross_tab = pd.crosstab(df['anime_name'], df[col])\n",
    "        distances = pdist(cross_tab.values, metric='jaccard')\n",
    "        similarity = 1 - squareform(distances)\n",
    "        return pd.DataFrame(similarity, index=cross_tab.index, columns=cross_tab.index)\n",
    "    \n",
    "    def compute_jaccard_array(df, col, arr):\n",
    "        cross_tab = pd.crosstab(df['anime_name'], df[col])\n",
    "        distances = arr\n",
    "        similarity = 1 - squareform(distances)\n",
    "        return pd.DataFrame(similarity, index=cross_tab.index, columns=cross_tab.index)\n",
    "        \n",
    "    df_jaccard = anime_df[[\"anime_name\", type]]\n",
    "\n",
    "\n",
    "    sim = precomputed\n",
    "    if sim is None:\n",
    "        sim = compute_jaccard(df_jaccard, type)\n",
    "        if title not in sim.index:\n",
    "            raise ValueError(f\"'{title}' not found in similarity data.\")\n",
    "        top = sim.loc[title].sort_values(ascending=False)[1:top_n+1]\n",
    "        return {\"top\": top}\n",
    "        \n",
    "    else:\n",
    "        sim_df = compute_jaccard_array(df_jaccard, type, sim)\n",
    "\n",
    "        if title not in sim_df.index:\n",
    "            raise ValueError(f\"'{title}' not found in similarity data.\")\n",
    "        top = sim_df.loc[title].sort_values(ascending=False)[1:top_n+1]\n",
    "        return {\"top\": top}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae70c94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top': anime_name\n",
       " One Punch Man 2nd Season             1.0\n",
       " One Punch Man 2nd Season Specials    1.0\n",
       " One Punch Man Specials               1.0\n",
       " One Punch Man: Road to Hero          1.0\n",
       " Zoids Shinseiki/Zero                 0.0\n",
       " 5-toubun no Hanayome                 0.0\n",
       " xxxHOLiC Shunmuki                    0.0\n",
       " 3-gatsu no Lion                      0.0\n",
       " Zero no Tsukaima                     0.0\n",
       " Zero no Tsukaima F                   0.0\n",
       " Name: One Punch Man, dtype: float64}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_by_jaccard(\"One Punch Man\", anime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee9ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_id_rec(title, anime_df, top_n, precomputed=None):\n",
    "    \"\"\"\n",
    "    tf_id_rec is a function that recommends the most similar anime \n",
    "    using TF-IDF cosine similarity based on the Synopsis field.\n",
    "\n",
    "    :param title: str\n",
    "        The anime title (anime_name) to base recommendations on.\n",
    "\n",
    "    :param anime_df: pd.DataFrame\n",
    "        DataFrame containing at least 'anime_name' and 'Synopsis' columns.\n",
    "\n",
    "    :param top_n: int\n",
    "        The number of top similar anime to return (excluding the anime itself).\n",
    "\n",
    "    :param precomputed: np.ndarray or None\n",
    "        Optional precomputed cosine similarity matrix. If provided, it will be used instead of recomputing.\n",
    "\n",
    "    :return: dict\n",
    "        A dictionary with:\n",
    "            { \"top\": pd.Series } — the top-N most similar anime and their similarity scores.\n",
    "    \"\"\"\n",
    "    \n",
    "# 1) verify the given title actually exists in the dataset\n",
    "    if title not in anime_df['anime_name'].values:\n",
    "        raise ValueError(\"'{0}' not found in dataset.\".format(title))\n",
    "\n",
    "    # 2) select only the columns we need and drop any rows where Synopsis is missing\n",
    "    df_content = anime_df[['anime_name', 'Synopsis']].dropna(subset=['Synopsis'])\n",
    "\n",
    "    # 3) build the TF-IDF matrix over all synopses\n",
    "    vectorizer = TfidfVectorizer(min_df=2, max_df=0.7, stop_words='english')\n",
    "    tfidf_mat = vectorizer.fit_transform(df_content['Synopsis'])\n",
    "    tfidf_df  = pd.DataFrame(\n",
    "        tfidf_mat.toarray(),\n",
    "        index=df_content['anime_name'],\n",
    "        columns=vectorizer.get_feature_names_out()\n",
    "    )\n",
    "\n",
    "    # 4) if a full cosine-similarity matrix was provided, reuse it\n",
    "    if precomputed is not None:\n",
    "        sim_df = pd.DataFrame(\n",
    "            precomputed,\n",
    "            index=tfidf_df.index,\n",
    "            columns=tfidf_df.index\n",
    "        )\n",
    "        sims = sim_df.loc[title].sort_values(ascending=False)\n",
    "        return {\"top\": sims}\n",
    "\n",
    "    # 5) otherwise compute similarity between the target and every other anime\n",
    "    target_vec   = tfidf_df.loc[title].values.reshape(1, -1)\n",
    "    other_df     = tfidf_df.drop(title, axis=0)\n",
    "    scores       = cosine_similarity(target_vec, other_df.values)[0]\n",
    "    result_series = pd.Series(scores, index=other_df.index)\n",
    "\n",
    "    # 6) pick the top_n highest-scoring titles\n",
    "    top_similar = result_series.sort_values(ascending=False).iloc[:top_n]\n",
    "\n",
    "    return {\"top\": top_similar}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a8d91b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tf_id_rec() missing 1 required positional argument: 'top_n'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtf_id_rec\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGrand Blue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manime_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: tf_id_rec() missing 1 required positional argument: 'top_n'"
     ]
    }
   ],
   "source": [
    "tf_id_rec(\"Grand Blue\", anime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed602401",
   "metadata": {},
   "source": [
    "<h1>USER BASED CF<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d71a9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2movie = rating_df.groupby('user_id')['anime_id'].apply(list).to_dict()\n",
    "movie2user = rating_df.groupby('anime_id')['user_id'].apply(list).to_dict()\n",
    "user_movie = zip(rating_df['user_id'], rating_df['anime_id'])\n",
    "user_movie_rating = zip(user_movie, rating_df['rating'])\n",
    "user_movie2rating = dict(user_movie_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89def2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(user2movie, user_movie2rating, user_avg, min_common):\n",
    "    \"\"\"\n",
    "    compute_similarity_matrix is a function that precomputes the similarity for each pair of users in \n",
    "    the training set and saves the similarity scores in a dictionary.\n",
    "    :param user2movie: a dictionary that maps each user to a list of movie_ids.\n",
    "    :param user_movie2rating: a dictionary that maps each (user, movie) pair to a rating.\n",
    "    :param user_avg: a dictionary of the average ratings for each user.\n",
    "    :param min_common: the required minimum number of common movies between a pair of movies to be eligible\n",
    "    for similarity calculation.\n",
    "    :return: a nested dictionary where the key is a user and the value is a dictionary of the similarity \n",
    "    score between the key user and all the other users.\n",
    "    \"\"\"\n",
    "    similarity_matrix = {}\n",
    "    all_users = list(user2movie.keys())\n",
    "    print(len(all_users))\n",
    "    for i, user1 in enumerate(all_users):\n",
    "        if user1 not in similarity_matrix:\n",
    "            similarity_matrix[user1] = {}\n",
    "    \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('{} users processed'.format(i + 1))\n",
    "\n",
    "        for j in range(i + 1, len(all_users)):\n",
    "            user2 = all_users[j]\n",
    "            pearson_similarity = calculate_pearson_similarity(user1, user2, user2movie, user_movie2rating, user_avg, min_common)\n",
    "            similarity_matrix[user1][user2] = pearson_similarity\n",
    "            \n",
    "            if user2 not in similarity_matrix:\n",
    "                similarity_matrix[user2] = {}\n",
    "            similarity_matrix[user2][user1] = pearson_similarity\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e55304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ saved user_similarity.gz  (845.34 MB)\n",
      "✓ saved item_similarity.gz  (27.89 MB)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  SAVE SIMILARITY MATRICES  —  plain nested-dict version\n",
    "# --------------------------------------------------------------\n",
    "import pickle, os, gzip\n",
    "\n",
    "def save_pickle(obj, path, compress=True):\n",
    "    \"\"\"Helper: write `obj` to *path* (optionally gzipped).\"\"\"\n",
    "    if compress:\n",
    "        with gzip.open(path + \".gz\", \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"✓ saved {path}.gz  ({os.path.getsize(path+'.gz')/1_048_576:.2f} MB)\")\n",
    "    else:\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"✓ saved {path}  ({os.path.getsize(path)/1_048_576:.2f} MB)\")\n",
    "\n",
    "# --- call it for both matrices --------------------------------\n",
    "save_pickle(user_similarity, \"user_similarity\")   # → user_similarity.pkl.gz\n",
    "save_pickle(item_similarity, \"item_similarity\")   # → item_similarity.pkl.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b60b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  FASTER CF PIPELINE  –  builds or loads top-K similarity and\n",
    "#  returns RMSE in a fraction of the previous run-time.\n",
    "# ============================================================\n",
    "import numpy as np, pandas as pd, pickle, os\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "K_NEIGH = 50        # keep only strongest 50 edges per row\n",
    "MIN_CO   = 5        # min common items/users to consider\n",
    "SEED     = 42\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. split\n",
    "train_df, test_df = train_test_split(\n",
    "    rating_df, test_size=0.2, stratify=rating_df[\"user_id\"], random_state=SEED\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. sparse utility builders\n",
    "uid2idx = {u:i for i,u in enumerate(train_df[\"user_id\"].unique())}\n",
    "iid2idx = {i:j for j,i in enumerate(train_df[\"anime_id\"].unique())}\n",
    "idx2uid = {i:u for u,i in uid2idx.items()}\n",
    "idx2iid = {j:i for j,i in iid2idx.items()}\n",
    "\n",
    "rows = train_df[\"user_id\"].map(uid2idx)\n",
    "cols = train_df[\"anime_id\"].map(iid2idx)\n",
    "data = train_df[\"rating\"].astype(float)\n",
    "R     = csr_matrix((data, (rows, cols)), shape=(len(uid2idx), len(iid2idx)))\n",
    "\n",
    "user_mean  = np.asarray(R.sum(1)).ravel() / (R != 0).sum(1).A1\n",
    "item_mean  = np.asarray(R.sum(0)).ravel() / (R != 0).sum(0).A1\n",
    "global_mean = data.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738aa3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user cosine similarity …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5561c902744445b49d280540bfd8cc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "top-50 user:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ saved user_sim.pkl\n",
      "Computing item cosine similarity …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa085ce75a34d8a96dcb4be0ef62bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "top-50 item:   0%|          | 0/9672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ saved item_sim.pkl\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, vstack\n",
    "import pickle, os, numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "K_NEIGH = 50   # keep strongest 50 links per row\n",
    "\n",
    "def topk_cosine(mat, kind, fname):\n",
    "    \"\"\"\n",
    "    Build (or load) a sparse top-K cosine-similarity matrix.\n",
    "      • mat   : CSR user-item or item-user matrix\n",
    "      • kind  : 'user' or 'item'  (for the progress‐bar label)\n",
    "      • fname : pickle file to cache the result\n",
    "    \"\"\"\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    print(f\"Computing {kind} cosine similarity …\")\n",
    "    full = cosine_similarity(mat, dense_output=False)   # very fast C-code\n",
    "\n",
    "    rows_topk = []\n",
    "    for i in tqdm(range(full.shape[0]), desc=f\"top-{K_NEIGH} {kind}\"):\n",
    "        row = full.getrow(i).tocoo()\n",
    "        if row.nnz > K_NEIGH:                              # prune heavy rows\n",
    "            idx = row.data.argsort()[::-1][:K_NEIGH]\n",
    "            rows_topk.append(\n",
    "                csr_matrix(\n",
    "                    (row.data[idx], (np.zeros_like(idx), row.col[idx])),\n",
    "                    shape=(1, full.shape[1])\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            rows_topk.append(row)\n",
    "\n",
    "    topk = vstack(rows_topk).tocsr()                       # <-- fix: sparse.vstack\n",
    "    with open(fname, \"wb\") as f:\n",
    "        pickle.dump(topk, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"✓ saved {fname}\")\n",
    "    return topk\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "user_sim = topk_cosine(R,   \"user\", \"user_sim.pkl\")      # (U × U)\n",
    "item_sim = topk_cosine(R.T, \"item\", \"item_sim.pkl\")      # (I × I)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51b5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. fast lookup helpers\n",
    "def predict_user_cf(u, i):\n",
    "    if (u not in uid2idx) or (i not in iid2idx):          # cold-start\n",
    "        return global_mean\n",
    "    ui, ii = uid2idx[u], iid2idx[i]\n",
    "    sims   = user_sim.getrow(ui).tocoo()\n",
    "    if sims.nnz == 0:                                     # isolated user\n",
    "        return user_mean[ui]\n",
    "    numer = 0.0; denom = 0.0\n",
    "    for s, v_idx in zip(sims.data, sims.col):\n",
    "        r_vi = R[v_idx, ii]\n",
    "        if r_vi == 0: continue\n",
    "        numer += s * (r_vi - user_mean[v_idx])\n",
    "        denom += abs(s)\n",
    "    return user_mean[ui] + numer/denom if denom else user_mean[ui]\n",
    "\n",
    "def predict_item_cf(u, i):\n",
    "    if (u not in uid2idx) or (i not in iid2idx):\n",
    "        return global_mean\n",
    "    ui, ii = uid2idx[u], iid2idx[i]\n",
    "    sims   = item_sim.getrow(ii).tocoo()\n",
    "    if sims.nnz == 0:\n",
    "        return item_mean[ii]\n",
    "    numer = 0.0; denom = 0.0\n",
    "    for s, j_idx in zip(sims.data, sims.col):\n",
    "        r_uj = R[ui, j_idx]\n",
    "        if r_uj == 0: continue\n",
    "        numer += s * (r_uj - item_mean[j_idx])\n",
    "        denom += abs(s)\n",
    "    return item_mean[ii] + numer/denom if denom else item_mean[ii]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d32f8e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-CF  RMSE : 1.3639\n",
      "Item-CF  RMSE : 1.2099\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4.  PARALLEL RMSE  (threads ➜ faster on GIL-releasing code)\n",
    "# ------------------------------------------------------------\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os, numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "N_WORKERS = max(4, os.cpu_count() // 2)   # sensible default\n",
    "\n",
    "def _square_error(row, predict_fn):       # helper for thread pool\n",
    "    return (row.rating - predict_fn(row.user_id, row.anime_id))**2\n",
    "\n",
    "def rmse_parallel(predict_fn, workers=N_WORKERS, batch=20_000):\n",
    "    \"\"\"\n",
    "    Compute RMSE on test_df using multithreading.\n",
    "      • workers : number of concurrent threads\n",
    "      • batch   : submit the jobs in chunks to keep memory low\n",
    "    \"\"\"\n",
    "    squared_errs = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=workers) as pool:\n",
    "        futures = []\n",
    "        for idx, row in enumerate(test_df.itertuples()):\n",
    "            futures.append(pool.submit(_square_error, row, predict_fn))\n",
    "\n",
    "            # optional: flush in batches to avoid thousands of open futures\n",
    "            if len(futures) == batch:\n",
    "                for f in as_completed(futures):\n",
    "                    squared_errs.append(f.result())\n",
    "                futures.clear()\n",
    "\n",
    "        # collect anything left in the final partial batch\n",
    "        for f in as_completed(futures):\n",
    "            squared_errs.append(f.result())\n",
    "\n",
    "    return sqrt(np.mean(squared_errs))\n",
    "\n",
    "\n",
    "print(\"User-CF  RMSE :\", round(rmse_parallel(predict_user_cf), 4))\n",
    "print(\"Item-CF  RMSE :\", round(rmse_parallel(predict_item_cf), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0069c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute user avg\n",
    "def compute_user_average(user2movie, user_movie2rating):\n",
    "    \"\"\"\n",
    "    compute_user_average is a function that calculates the average rating for each user in the dataset.\n",
    "    :param user2movie: a dictionary that maps each user to a list of movie_ids.\n",
    "    :param user_movie2rating: a dictionary that maps each (user, movie) pair to a rating.\n",
    "    :return: a dictionary containing the average rating for each user where the key is the user and the\n",
    "    value is the average rating.\n",
    "    \"\"\"\n",
    "    user_avg = {}\n",
    "    for user, movies in user2movie.items():\n",
    "        ratings = [user_movie2rating[(user, movie)] for movie in movies]\n",
    "        user_avg[user] = np.mean(ratings)\n",
    "    return user_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74c6ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_recs(recs, rating_df, max_lines=10):\n",
    "    \"\"\"\n",
    "    Show a recommendation list in a readable table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    recs : list[tuple(int, float)]\n",
    "        Output of a recommender, e.g.\n",
    "        [(19, 10.0), (32, 9.7), …]  where\n",
    "        rec[0] = anime_id   and   rec[1] = predicted / hybrid score.\n",
    "    rating_df : pd.DataFrame\n",
    "        The ratings table that already lives in memory.  \n",
    "        Must contain the columns  ['anime_id', 'anime_name'].\n",
    "        (Duplicates are fine – we just grab the first match.)\n",
    "    max_lines : int, default 10\n",
    "        How many rows to print.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- build a quick lookup:  anime_id → anime_name -------------\n",
    "    id2name = (\n",
    "        rating_df[[\"anime_id\", \"anime_name\"]]\n",
    "        .drop_duplicates(\"anime_id\")\n",
    "        .set_index(\"anime_id\")[\"anime_name\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # --- nicely formatted output ---------------------------------\n",
    "    print(\"┌────────┬──────────────────────────────────────────────────┬────────┐\")\n",
    "    print(\"│ Rank   │ Anime title                                      │ Score  │\")\n",
    "    print(\"├────────┼──────────────────────────────────────────────────┼────────┤\")\n",
    "\n",
    "    for rank, (aid, score) in enumerate(recs[:max_lines], start=1):\n",
    "        title = id2name.get(aid, f\"<? unknown id {aid} ?>\")\n",
    "        print(f\"│ {rank:>3}    │ {title[:50]:<50} │ {score:>6.2f} │\")\n",
    "\n",
    "    print(\"└────────┴──────────────────────────────────────────────────┴────────┘\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8e112",
   "metadata": {},
   "source": [
    "##Item-Based CF##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#  HYBRID COLLABORATIVE FILTER \n",
    "#  -------------------------------------------------------------\n",
    "#  · user-based CF  (top-K cosine on USER × ITEM matrix)\n",
    "#  · item-based CF  (top-K cosine on ITEM × USER matrix)\n",
    "#  · HybridCF = α·userCF + (1-α)·itemCF\n",
    "# =============================================================\n",
    "\n",
    "import pandas as pd, numpy as np, pickle, os\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ---------------- 1. helper dictionaries ---------------------\n",
    "user2movie = rating_df.groupby(\"user_id\")[\"anime_id\"].apply(list).to_dict()\n",
    "movie2user = rating_df.groupby(\"anime_id\")[\"user_id\"].apply(list).to_dict()\n",
    "user_movie2rating = {(r.user_id, r.anime_id): r.rating for r in rating_df.itertuples()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b0ad030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- 2. sparse USER × ITEM matrix ---------------\n",
    "uid2idx = {u:i for i,u in enumerate(rating_df[\"user_id\"].unique())}\n",
    "iid2idx = {i:j for j,i in enumerate(rating_df[\"anime_id\"].unique())}\n",
    "idx2iid = {j:i for i,j in iid2idx.items()}\n",
    "\n",
    "rows = rating_df[\"user_id\"].map(uid2idx)\n",
    "cols = rating_df[\"anime_id\"].map(iid2idx)\n",
    "data = rating_df[\"rating\"].astype(float)\n",
    "R = csr_matrix((data, (rows, cols)), shape=(len(uid2idx), len(iid2idx)))\n",
    "\n",
    "user_mean  = np.asarray(R.sum(1)).ravel() / (R != 0).sum(1).A1\n",
    "item_mean  = np.asarray(R.sum(0)).ravel() / (R != 0).sum(0).A1\n",
    "global_mean = data.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d56220de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1992af80a47f444f8c9d10b5a969061c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "top-50 prune:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cc027e718b4d00821c7d96a38e3876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "top-50 prune:   0%|          | 0/10015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------- 3. cosine similarity (top-K pruning) -------\n",
    "def topk_cosine(mat, K=50):\n",
    "    sim = cosine_similarity(mat, dense_output=False)          # CSR × CSR\n",
    "    trimmed = []\n",
    "    for i in tqdm(range(sim.shape[0]), desc=f\"top-{K} prune\"):\n",
    "        row = sim.getrow(i).tocoo()\n",
    "        idx = row.data.argsort()[::-1][:K]                    # keep best-K\n",
    "        trimmed.append(\n",
    "            csr_matrix((row.data[idx], (np.zeros_like(idx), row.col[idx])),\n",
    "                       shape=(1, sim.shape[1]))\n",
    "        )\n",
    "    return vstack(trimmed).tocsr()\n",
    "\n",
    "user_sim = topk_cosine(R,   K=50)      # (U × U) sparse\n",
    "item_sim = topk_cosine(R.T, K=50)      # (I × I) sparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a12b6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- 4. rating predictors -----------------------\n",
    "def predict_user_cf(u, i, sim_cut=0.05):\n",
    "    if (u not in uid2idx) or (i not in iid2idx): return global_mean\n",
    "    ui, ii = uid2idx[u], iid2idx[i]\n",
    "    sims   = user_sim.getrow(ui).tocoo()\n",
    "    num=den=0.0\n",
    "    for s,v in zip(sims.data, sims.col):\n",
    "        if s < sim_cut: break\n",
    "        r_vi = R[v, ii]\n",
    "        if r_vi==0: continue\n",
    "        num += s * (r_vi - user_mean[v])\n",
    "        den += abs(s)\n",
    "    return user_mean[ui] + num/den if den else user_mean[ui]\n",
    "\n",
    "def predict_item_cf(u, i, sim_cut=0.05):\n",
    "    if (u not in uid2idx) or (i not in iid2idx): return global_mean\n",
    "    ui, ii = uid2idx[u], iid2idx[i]\n",
    "    sims   = item_sim.getrow(ii).tocoo()\n",
    "    num=den=0.0\n",
    "    for s,j in zip(sims.data, sims.col):\n",
    "        if s < sim_cut: break\n",
    "        r_uj = R[ui, j]\n",
    "        if r_uj==0: continue\n",
    "        num += s * (r_uj - item_mean[j])\n",
    "        den += abs(s)\n",
    "    return item_mean[ii] + num/den if den else item_mean[ii]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0248ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- 5. recommendation helpers -----------------\n",
    "def uCF_list(user, top_n=500):\n",
    "    seen = set(user2movie.get(user, []))\n",
    "    cand = [m for m in movie2user if m not in seen]\n",
    "    scores = {m: predict_user_cf(user, m) for m in cand}\n",
    "    return sorted(scores.items(), key=lambda x:x[1], reverse=True)[:top_n]\n",
    "\n",
    "def itemCF_list(user, top_n=500):\n",
    "    seen = set(user2movie.get(user, []))\n",
    "    cand = [m for m in movie2user if m not in seen]\n",
    "    scores = {m: predict_item_cf(user, m) for m in cand}\n",
    "    return sorted(scores.items(), key=lambda x:x[1], reverse=True)[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "032a6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- 6. HYBRID recommender ----------------------\n",
    "def HybridCF(user, top_n=10, alpha=0.6):\n",
    "    u_preds = dict(uCF_list(user, top_n=1000))\n",
    "    i_preds = dict(itemCF_list(user, top_n=1000))\n",
    "    movies  = set(u_preds)|set(i_preds)\n",
    "    hybrid  = {}\n",
    "    for m in movies:\n",
    "        if m in u_preds and m in i_preds:\n",
    "            hybrid[m] = alpha*u_preds[m] + (1-alpha)*i_preds[m]\n",
    "        elif m in u_preds:\n",
    "            hybrid[m] = u_preds[m]\n",
    "        else:\n",
    "            hybrid[m] = i_preds[m]\n",
    "    return sorted(hybrid.items(), key=lambda x:x[1], reverse=True)[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8317bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid recommendations for user 36:\n",
      "\n",
      "Kore ga UFO da! Soratobu Enban                 (17.86)\n",
      "Futatsu no Kurumi                              (17.86)\n",
      "Glass no Kamen: Sen no Kamen wo Motsu Shoujo   (16.36)\n",
      "Penguin's Memory: Shiawase Monogatari          (16.11)\n",
      "Moonfesta                                      (15.86)\n",
      "True Tears Epilogue                            (15.49)\n",
      "Genshiken Nidaime OVA                          (15.27)\n",
      "Houkago Initiation                             (14.86)\n",
      "Zetsubou Funsai Shoujo ∞ Amida                 (14.86)\n",
      "Amada Anime Series: Super Mario Brothers       (14.06)\n"
     ]
    }
   ],
   "source": [
    "# ------------ example run (using rating_df for the lookup) -----------\n",
    "TARGET_USER = 36\n",
    "print(f\"\\nHybrid recommendations for user {TARGET_USER}:\\n\")\n",
    "\n",
    "# pre-build a fast ID→name map from rating_df\n",
    "id2name = rating_df.drop_duplicates(\"anime_id\") \\\n",
    "                   .set_index(\"anime_id\")[\"anime_name\"]  # Series\n",
    "\n",
    "for mid, score in HybridCF(TARGET_USER, top_n=10, alpha=0.6):\n",
    "    title = id2name.get(mid, f\"(id {mid})\")   # graceful fallback\n",
    "    print(f\"{title:<45}  ({score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3b01f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = uCF_list(36, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49b7a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬──────────────────────────────────────────────────┬────────┐\n",
      "│ Rank   │ Anime title                                      │ Score  │\n",
      "├────────┼──────────────────────────────────────────────────┼────────┤\n",
      "│   1    │ Kimi to Boku. 2                                    │  12.39 │\n",
      "│   2    │ Texhnolyze                                         │  11.99 │\n",
      "│   3    │ Megalo Box                                         │  11.74 │\n",
      "│   4    │ Kimi to Boku.                                      │  11.39 │\n",
      "│   5    │ JoJo no Kimyou na Bouken Part 4: Diamond wa Kudake │  10.92 │\n",
      "│   6    │ Yama no Susume: Second Season                      │  10.91 │\n",
      "│   7    │ Yakusoku no Neverland                              │  10.91 │\n",
      "│   8    │ Kaguya-sama wa Kokurasetai: Tensai-tachi no Renai  │  10.91 │\n",
      "│   9    │ Kizumonogatari III: Reiketsu-hen                   │  10.84 │\n",
      "│  10    │ Owarimonogatari 2nd Season                         │  10.84 │\n",
      "└────────┴──────────────────────────────────────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "pretty_print_recs(rec, rating_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
